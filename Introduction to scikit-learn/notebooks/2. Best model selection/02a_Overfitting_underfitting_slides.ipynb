{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a781969-19f0-4bf7-88e9-cd4794f2ea65",
   "metadata": {},
   "source": [
    "# Overfitting and underfitting\n",
    "\n",
    "Understand when and why a model does or does not generalize well on unseen data.\n",
    "\n",
    "<img src=\"../figures/scikit-learn-logo.svg\">\n",
    "\n",
    " \n",
    "\n",
    "The slides cover the topics of overfitting and underfitting, \n",
    "which are important concepts to understand why a model does or \n",
    "does not generalize well to new data.\n",
    "\n",
    "\n",
    "---\n",
    "# Which data fit do you prefer?\n",
    "<table><tr>\n",
    "<td> <img src=\"../figures/linear_ols.svg\" width=80%/> </td>\n",
    "<td> <img src=\"../figures/linear_splines.svg\" width=80%/> </td>\n",
    "</tr></table>\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "Let's' start with a simple question: given the following data, which of\n",
    "the two models do you prefer? Let's take a moment to think about it.\n",
    "\n",
    "Most people reply that they prefer the one with the straight line.\n",
    "However, the one with the wiggly line fits the data perfectly, doesn't it?\n",
    "So why might we prefer the straight line?\n",
    "\n",
    "---\n",
    "# Which data fit do you prefer?\n",
    "<table><tr>\n",
    "<td> <img src=\"../figures/linear_ols_test.svg\" width=80%> </td>\n",
    "<td> <img src=\"../figures/linear_splines_test.svg\" width=80%> </td>\n",
    " </tr></table>   \n",
    "**On new data**\n",
    "\n",
    " \n",
    "\n",
    "Answering this question might be hard. However, in the context of machine\n",
    "learning we aim at creating models that generalize. Hence, the good way \n",
    "of framing the question is: how will the model perform on new data?\n",
    "\n",
    "---\n",
    "# Which data fit do you prefer?\n",
    "<table><tr>\n",
    "<td> <img src=\"../figures/ols_simple_test.svg\" width=80%> </td>\n",
    " <td><img src=\"../figures/splines_cubic_test.svg\" width=80%> </td>\n",
    "</tr></table>\n",
    "    \n",
    "**A harder example**\n",
    "\n",
    " \n",
    "\n",
    "How about a slightly harder example? Which one should we choose?\n",
    "This is a difficult question.\n",
    "\n",
    "In this lesson, we will study useful concepts to understand these\n",
    "tradeoffs.\n",
    "\n",
    "\n",
    "---\n",
    "# Varying model complexity\n",
    "\n",
    "**polynomial** <img src=\"../figures/polynomial_overfit_truth.svg\" width=40%>\n",
    "\n",
    "* Data generated by a random process\n",
    "\n",
    "    - Sample a value of the input *x*\n",
    "\n",
    "    - Transform it with a 9th-degree polynomial\n",
    "\n",
    "    - Add some noise to get the output *y*\n",
    "\n",
    " \n",
    "\n",
    "In the latest example, we have generated the data so that *y* is a\n",
    "9th-degree polynomial function of *X*, with some additional noise.\n",
    "\n",
    "\n",
    "\n",
    "# Varying model complexity\n",
    "\n",
    "**polynomial** \n",
    "    <img src=\"../figures/polynomial_overfit_0.svg\" width=40%>\n",
    "\n",
    "    \n",
    "- Data generated by a random process\n",
    "\n",
    "- This process is unknown\n",
    "\n",
    "- We can only access the observations\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "# Varying model complexity\n",
    "\n",
    "**polynomial** <img src=\"../figures/polynomial_overfit_1.svg\" width=40%>\n",
    "\n",
    "- Data generated by a random process\n",
    "\n",
    "- This process is unknown\n",
    "\n",
    "- We can only access the observations\n",
    "\n",
    "- Fit polynomials of various degrees\n",
    "\n",
    " \n",
    "\n",
    "What we will now do is fit to this data polymonials of various degrees.\n",
    "We'll start with a polynomial of degree 1: a simple linear regression of\n",
    "*y* on *X*. Clearly, this model does not explain well the data.\n",
    "\n",
    "---\n",
    "# Varying model complexity\n",
    "\n",
    "**polynomial** <img src=\"../figures/polynomial_overfit_2.svg\" width=40%>\n",
    "\n",
    "- Data generated by a random process\n",
    "\n",
    "- This process is unknown\n",
    "\n",
    "- We can only access the observations\n",
    "\n",
    "- Fit polynomials of various degrees\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "If we fit a polynomial of degree 2, it is better.\n",
    "\n",
    "---\n",
    "# Varying model complexity\n",
    "\n",
    "**polynomial** <img src=\"../figures/polynomial_overfit_5.svg\" width=40%>\n",
    "\n",
    "- Data generated by a random process\n",
    "\n",
    "- This process is unknown\n",
    "\n",
    "- We can only access the observations\n",
    "\n",
    "- Fit polynomials of various degrees\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "Polynomial of degree 5: it's hard to tell whether it explains the data\n",
    "better\n",
    "\n",
    "---\n",
    "# Varying model complexity\n",
    "\n",
    "**polynomial** <img src=\"../figures/polynomial_overfit_9.svg\" width=40%>\n",
    "\n",
    "- Data generated by a random process\n",
    "\n",
    "- This process is unknown\n",
    "\n",
    "- We can only access the observations\n",
    "\n",
    "- Fit polynomials of various degrees\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "And if we go all the way up to degree 9, the fit looks really bad\n",
    "\n",
    "---\n",
    "# Varying model complexity\n",
    "\n",
    "**polynomial** <img src=\"../figures/polynomial_overfit.svg\" width=40%>\n",
    "\n",
    "- Data generated by a random process\n",
    "\n",
    "- This process is unknown\n",
    "\n",
    "- We can only access the observations\n",
    "\n",
    "- Fit polynomials of various degrees\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "The actual function that was used to generate the data looks like this,\n",
    "though we added observational noise.\n",
    "\n",
    "---\n",
    "# Overfit: model too complex\n",
    "\n",
    "<img src=\"../figures/polynomial_overfit_simple_legend.svg\" width=40%>\n",
    "\n",
    "**Model too complex for the data:**\n",
    "\n",
    "* Its best possible fit would approximate well the generative process\n",
    "\n",
    "* However, its flexibility captures noise\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "In the case of the 9th-degree polynomial, the problem we face is\n",
    "that the model we're using is too complex for the data at hand. This\n",
    "problem is known as overfiting in machine learning. \n",
    "With such a rich model, its best possible fit would approximate well the \n",
    "data-generating process.\n",
    "Indeed, here we are fitting a polynomial of degree 9 on data generated\n",
    "with a polynomial of degree 9. However, due to the limited data,\n",
    "the model fit captures noise because it is too flexible.\n",
    "\n",
    "--\n",
    "\n",
    "**Not enough data** &nbsp; &nbsp; **Too much noise**\n",
    "\n",
    " \n",
    "\n",
    "This problem is typically encountered when there is not enough data, or too\n",
    "much noise.\n",
    "\n",
    "---\n",
    "# Underfit: model too simple\n",
    "\n",
    "<img src=\"../figures/polynomial_underfit_simple.svg\" width=40%>\n",
    "\n",
    "Model too simple for the data:\n",
    "\n",
    "* Its best fit does not approximate well the generative process\n",
    "\n",
    "* Yet it captures little noise\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "At the opposite end of the spectrum, when we are fitting a polynomial of\n",
    "degree 1, the model is too simple for the data at hand. We say that it\n",
    "underfits. Its best possible fit cannot approximate well the\n",
    "data-generating process. On the positive side, it captures little noise,\n",
    "As a consequence even with limited data, the empirical fit is close to\n",
    "the best possible fit on an infinite amount of data.\n",
    "\n",
    "\n",
    "\n",
    "**Plenty of data** &nbsp; &nbsp; **Low noise**\n",
    "\n",
    " \n",
    "\n",
    "Underfit is more common when there is plenty of data compared to the\n",
    "complexity of the model, or in low-noise situations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Take home messages\n",
    "\n",
    "\n",
    "Models too complex for the data **overfit**:\n",
    "\n",
    "\n",
    "- they explain too well the data that they have seen\n",
    "- they do not generalize\n",
    "\n",
    "\n",
    "Models too simple for the data **underfit**:\n",
    "\n",
    "\n",
    "- they capture no noise\n",
    "- they are limited by their expressivity\n",
    "\n",
    "\n",
    "How to find the right trade-off?\n",
    "\n",
    " \n",
    "\n",
    "When the models are too complex for the data at hand, they overfit. This\n",
    "means that they explain too well the data that they have seen as they\n",
    "capture noise, and thus do not generalize to new data.\n",
    "\n",
    "On the opposite, when models are too simple for the data at hand, they\n",
    "underfit. This means that they capture no noise, but they also don't capture\n",
    "all the structured variations of the data: their ability to generalize \n",
    "is then limited by their expressivity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74bc27-f4f9-4af9-a0c4-a816247a3e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_ts_istec",
   "language": "python",
   "name": "msc_ts_istec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
