{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69bc1b5b-35b1-4860-a2da-6a92c3986dd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bias and Variance\n",
    "\n",
    "A statistical view of Underfitting and Overfitting.\n",
    "\n",
    "<img src=\"../figures/scikit-learn-logo.svg\">\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "In this slide, we will discuss the bias-variance tradeoff, which is\n",
    "useful to give a statistical view on underfitting and overfitting.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70081d2-9322-4031-9576-bea811f64daa",
   "metadata": {},
   "source": [
    "# Resampling the training set\n",
    "\n",
    "- A limited amount of training data\n",
    "\n",
    "- Training set is a small random subset of all possible observations\n",
    "\n",
    "- What is the impact of this choice of training set on the learned prediction\n",
    "  function?\n",
    "\n",
    "\n",
    " \n",
    "Machine learning operates with finite training set:\n",
    "\n",
    "We label an arbitrarily random subset of all possible observations because\n",
    "labeling all the possible observations would be too costly.\n",
    "\n",
    "What if we used a different training set?\n",
    "\n",
    "- How different would the resulting learned prediction functions be?\n",
    "\n",
    "- What would be their average test error?\n",
    "\n",
    "---\n",
    "# Overfit: variance\n",
    "\n",
    " <table><tr>\n",
    "<td> <img src=\"../figures/polynomial_overfit_resample_0.svg\" width=\"80%\"> </td>\n",
    "<td> <img src=\"../figures/target_variance_0.svg\" class=\"shift-up\" width=\"50%\"></td>\n",
    " </tr></table> \n",
    " \n",
    "Let's illustrate the concept of bias using the analogy of shooting arrows on a\n",
    "target.\n",
    "\n",
    "A cross on the target represents the result a model obtained by applying\n",
    "the learning algorithm to a random training set with a given finite size.\n",
    "\n",
    "The perfect model would be located at the center of the target. The distance to\n",
    "the target represents the test error (computed with an infinite test data).\n",
    "\n",
    "---\n",
    "# Overfit: variance\n",
    "\n",
    " <table><tr>\n",
    "<td> <img src=\"../figures/polynomial_overfit_resample_1.svg\" width=\"80%\"> </td>\n",
    "<td> <img src=\"../figures/target_variance_1.svg\" class=\"shift-up\" width=\"50%\"></td>\n",
    " </tr></table> \n",
    " \n",
    "If we were to train our high flexibility degree 9 polynomial model on an\n",
    "alternative sample of the training set, we could get a very different\n",
    "prediction function.\n",
    "\n",
    "On the target, that would be represented an arrow in a completely\n",
    "different location.\n",
    "\n",
    "\n",
    "---\n",
    "# Overfit: variance\n",
    "\n",
    "\n",
    " <table><tr>\n",
    "<td> <img src=\"../figures/polynomial_overfit_resample_2.svg\" width=\"80%\"> </td>\n",
    "<td> <img src=\"../figures/target_variance_2.svg\" class=\"shift-up\" width=\"50%\"></td>\n",
    " </tr></table>\n",
    "Another resample, another very different prediction function.\n",
    "\n",
    "---\n",
    "# Overfit: variance\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"../figures/polynomial_overfit_resample_all.svg\" width=\"80%\"> </td>\n",
    "<td> <img src=\"../figures/target_variance.svg\" class=\"shift-up\" width=\"50%\"> </td>\n",
    " </tr></table>\n",
    " \n",
    "If we consider all the possible models trained on resampled training sets we\n",
    "can see the overfitting behavior.\n",
    "\n",
    "The overfitting problem is one of variance: on average, the predictions are not\n",
    "necessarily off, but each tend to fall far from the target. This can be seen by\n",
    "their large spread around the best possible prediction. A useful mental picture\n",
    "is that of the spread of arrows on a target.\n",
    "\n",
    "For our machine learning example, this situation corresponds to a high\n",
    "complexity model class that is affected by how the noise in the data generating\n",
    "process makes the observations vary from one small training set to another.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c59e1c-c5a1-40a2-87e0-9c0f1effc02a",
   "metadata": {},
   "source": [
    "# Underfit: bias\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"../figures/polynomial_underfit_resample_0.svg\" width=\"80%\"> </td>\n",
    "<td> <img src=\"../figures/target_bias_0.svg\" class=\"shift-up\" width=\"50%\"> </td>\n",
    " </tr></table>\n",
    "\n",
    "Let's now consider an underfitting model: polynomial of degree 1 (which is just\n",
    "a linear prediction function).\n",
    "\n",
    "Since the true generative process is non-linear, our fitted prediction function\n",
    "is bound to make prediction errors for some regions of the input space.\n",
    "\n",
    "---\n",
    "# Underfit: bias\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"../figures/polynomial_underfit_resample_1.svg\" width=\"80%\"> </td>\n",
    "<td> <img src=\"../figures/target_bias_1.svg\" class=\"shift-up\" width=\"50%\"> </td>\n",
    "</tr></table>\n",
    "\n",
    "Upon resampling the training set, one can see that the resulting training\n",
    "function stays very similar: the slope moves a bit.\n",
    "\n",
    "---\n",
    "# Underfit: bias\n",
    "\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"../figures/polynomial_underfit_resample_2.svg\" width=\"80%\"> </td>\n",
    "<td> <img src=\"../figures/target_bias_2.svg\" class=\"shift-up\" width=\"50%\"> </td>\n",
    "</tr></table>\n",
    "\n",
    "Even more importantly, for a given region of the input space, the underfitting\n",
    "models tend to make similar kinds of prediction errors.\n",
    "\n",
    "---\n",
    "# Underfit: bias\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"../figures/polynomial_underfit_resample_all.svg\" width=\"80%\"> </td>\n",
    "<td> <img src=\"../figures/target_bias.svg\" class=\"shift-up\" width=\"50%\"> </td>\n",
    "</tr></table>\n",
    "\n",
    "Underfitting leads to systematic biases: the predictions cannot be on target on\n",
    "average, because the model that we used to predict is systematically off the\n",
    "data-generating process.\n",
    "\n",
    "On the figure on the left, if we choose a linear model with generated data\n",
    "coming from a non-linear generative process, whatever the choice of the training\n",
    "set, our trained model will tend to make systematic under-predictions on the\n",
    "edges of the domain and over-predictions in the middle of the domain.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde9ca0-26f1-4b47-9515-d6a0456ea561",
   "metadata": {},
   "source": [
    "# Underfit versus overfit\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"../figures/target_bias.svg\" width=\"60%\"> </td>\n",
    "<td> <img src=\"../figures/target_variance.svg\" width=\"60%\"></td>\n",
    "</tr></table>\n",
    "\n",
    "<h1><center> Bias &nbsp; &nbsp; Variance </center></h1>\n",
    "\n",
    "- Bias systematic error , not good on average\n",
    "- Variance random erro, good on average\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "This bias-variance tradeoff is classic in statistics. Often, adding a\n",
    "little bit of bias helps reducing the variance. For instance, as with\n",
    "throwing darts at a target, throwing the darts less strong might\n",
    "lead to being below the target on average, but with less scatter.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451a6491-8f25-4eb3-ac00-9665320ace26",
   "metadata": {},
   "source": [
    "# Take home messages\n",
    "\n",
    "\n",
    "**High bias** == **underfitting**:\n",
    "\n",
    "\n",
    "- systematic prediction errors\n",
    "- the model prefers to ignore some aspects of the data\n",
    "- mispecified models\n",
    "\n",
    "\n",
    "**High variance** == **overfitting**:\n",
    "\n",
    "\n",
    "- prediction errors without obvious structure\n",
    "- small change in the training set, large change in model\n",
    "- unstable models\n",
    "\n",
    "\n",
    "The bias can come from the choice of the model family.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb0291-9001-434b-b339-bfd5f94deced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_ts_istec",
   "language": "python",
   "name": "msc_ts_istec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
